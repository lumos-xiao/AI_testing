{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#参考https://github.com/tensorflow/cleverhans/blob/master/cleverhans_tutorials/mnist_tutorial_pytorch.py\n",
    "#加上这些，如果你的python版本是python2.X，你也得按照python3.X那样使用这些函数。\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from __future__ import unicode_literals\n",
    "\n",
    "import logging\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from cleverhans.loss import CrossEntropy\n",
    "from cleverhans.dataset import MNIST\n",
    "from cleverhans.utils_tf import model_eval\n",
    "from cleverhans.train import train\n",
    "from cleverhans.attacks import FastGradientMethod\n",
    "from cleverhans.utils import AccuracyReport, set_log_level\n",
    "from cleverhans_tutorials.tutorial_models import ModelBasicCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义全局变量\n",
    "\n",
    "NB_EPOCHS = 6\n",
    "BATCH_SIZE = 128\n",
    "LEARNING_RATE = 0.001\n",
    "CLEAN_TRAIN = True\n",
    "BACKPROP_THROUGH_ATTACK = False\n",
    "NB_FILTERS = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_devices:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 2018-12-03 10:54:38,576 cleverhans] Epoch 0 took 7.032440662384033 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy on legitimate examples: 0.9882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 2018-12-03 10:54:42,088 cleverhans] Epoch 1 took 3.0253713130950928 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy on legitimate examples: 0.9899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 2018-12-03 10:54:45,455 cleverhans] Epoch 2 took 2.997742176055908 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy on legitimate examples: 0.9923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 2018-12-03 10:54:48,834 cleverhans] Epoch 3 took 3.0095574855804443 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy on legitimate examples: 0.9924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 2018-12-03 10:54:52,227 cleverhans] Epoch 4 took 3.0277392864227295 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy on legitimate examples: 0.9927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 2018-12-03 10:54:55,581 cleverhans] Epoch 5 took 2.9836318492889404 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy on legitimate examples: 0.9929\n",
      "Test accuracy on adversarial examples: 0.1432\n",
      "Repeating the process, using adversarial training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/opt/anaconda2/envs/book5/lib/python3.6/site-packages/cleverhans/loss.py:41: UserWarning: callable attacks are deprecated, switch to an Attack subclass. callable attacks will not be supported after 2019-05-05.\n",
      "  warnings.warn(\"callable attacks are deprecated, switch to an Attack \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_devices:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 2018-12-03 10:55:05,318 cleverhans] Epoch 0 took 7.10737156867981 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy on legitimate examples: 0.9790\n",
      "Test accuracy on adversarial examples: 0.8333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 2018-12-03 10:55:13,398 cleverhans] Epoch 1 took 6.90619683265686 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy on legitimate examples: 0.9865\n",
      "Test accuracy on adversarial examples: 0.8988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 2018-12-03 10:55:21,237 cleverhans] Epoch 2 took 6.907305717468262 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy on legitimate examples: 0.9895\n",
      "Test accuracy on adversarial examples: 0.9185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 2018-12-03 10:55:29,093 cleverhans] Epoch 3 took 6.93480372428894 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy on legitimate examples: 0.9901\n",
      "Test accuracy on adversarial examples: 0.9344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 2018-12-03 10:55:36,936 cleverhans] Epoch 4 took 6.930524110794067 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy on legitimate examples: 0.9893\n",
      "Test accuracy on adversarial examples: 0.9325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 2018-12-03 10:55:44,797 cleverhans] Epoch 5 took 6.94186544418335 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy on legitimate examples: 0.9899\n",
      "Test accuracy on adversarial examples: 0.9355\n"
     ]
    }
   ],
   "source": [
    "def mnist_tutorial(train_start=0, train_end=60000, test_start=0,\n",
    "                   test_end=10000, nb_epochs=NB_EPOCHS, batch_size=BATCH_SIZE,\n",
    "                   learning_rate=LEARNING_RATE,\n",
    "                   clean_train=CLEAN_TRAIN,\n",
    "                   testing=False,\n",
    "                   backprop_through_attack=BACKPROP_THROUGH_ATTACK,\n",
    "                   nb_filters=NB_FILTERS, num_threads=None,\n",
    "                   label_smoothing=0.1):\n",
    "\n",
    "  # Object used to keep track of (and return) key accuracies\n",
    "  report = AccuracyReport()\n",
    "\n",
    "  # Set TF random seed to improve reproducibility\n",
    "  tf.set_random_seed(1234)\n",
    "\n",
    "  # Set logging level to see debug information\n",
    "  set_log_level(logging.DEBUG)\n",
    "\n",
    "  # Create TF session\n",
    "  #intra_op_parallelism_threads 控制运算符op内部的并行当运算符op为单一运算符，并且内部可以实现并行时，\n",
    "  #  如矩阵乘法，reduce_sum之类的操作，可以通过设置intra_op_parallelism_threads参数来并行, intra代表内部\n",
    "  if num_threads:\n",
    "    config_args = dict(intra_op_parallelism_threads=1)\n",
    "  else:\n",
    "    config_args = {}\n",
    "  sess = tf.Session(config=tf.ConfigProto(**config_args))\n",
    "\n",
    "  # Get MNIST data\n",
    "  mnist = MNIST(train_start=train_start, train_end=train_end,\n",
    "                test_start=test_start, test_end=test_end)\n",
    "  x_train, y_train = mnist.get_set('train')\n",
    "  x_test, y_test = mnist.get_set('test')\n",
    "\n",
    "  # Use Image Parameters\n",
    "  img_rows, img_cols, nchannels = x_train.shape[1:4]\n",
    "  nb_classes = y_train.shape[1]\n",
    "\n",
    "  # Define input TF placeholder\n",
    "  x = tf.placeholder(tf.float32, shape=(None, img_rows, img_cols,\n",
    "                                        nchannels))\n",
    "  y = tf.placeholder(tf.float32, shape=(None, nb_classes))\n",
    "\n",
    "  # Train an MNIST model\n",
    "  train_params = {\n",
    "      'nb_epochs': nb_epochs,\n",
    "      'batch_size': batch_size,\n",
    "      'learning_rate': learning_rate\n",
    "  }\n",
    "  eval_params = {'batch_size': batch_size}\n",
    "  fgsm_params = {\n",
    "      'eps': 0.3,\n",
    "      'clip_min': 0.,\n",
    "      'clip_max': 1.\n",
    "  }\n",
    "  rng = np.random.RandomState([2017, 8, 30])\n",
    "\n",
    "  def do_eval(preds, x_set, y_set, report_key, is_adv=None):\n",
    "    acc = model_eval(sess, x, y, preds, x_set, y_set, args=eval_params)\n",
    "    setattr(report, report_key, acc)\n",
    "    if is_adv is None:\n",
    "      report_text = None\n",
    "    elif is_adv:\n",
    "      report_text = 'adversarial'\n",
    "    else:\n",
    "      report_text = 'legitimate'\n",
    "    if report_text:\n",
    "      print('Test accuracy on %s examples: %0.4f' % (report_text, acc))\n",
    "\n",
    "  if clean_train:\n",
    "    model = ModelBasicCNN('model1', nb_classes, nb_filters)\n",
    "    preds = model.get_logits(x)\n",
    "    loss = CrossEntropy(model, smoothing=label_smoothing)\n",
    "\n",
    "    def evaluate():\n",
    "      do_eval(preds, x_test, y_test, 'clean_train_clean_eval', False)\n",
    "\n",
    "    train(sess, loss, x_train, y_train, evaluate=evaluate,\n",
    "          args=train_params, rng=rng, var_list=model.get_params())\n",
    "\n",
    "    # Calculate training error\n",
    "    if testing:\n",
    "      do_eval(preds, x_train, y_train, 'train_clean_train_clean_eval')\n",
    "\n",
    "    # Initialize the Fast Gradient Sign Method (FGSM) attack object and\n",
    "    # graph\n",
    "    fgsm = FastGradientMethod(model, sess=sess)\n",
    "    adv_x = fgsm.generate(x, **fgsm_params)\n",
    "    preds_adv = model.get_logits(adv_x)\n",
    "\n",
    "    # Evaluate the accuracy of the MNIST model on adversarial examples\n",
    "    do_eval(preds_adv, x_test, y_test, 'clean_train_adv_eval', True)\n",
    "\n",
    "    # Calculate training error\n",
    "    if testing:\n",
    "      do_eval(preds_adv, x_train, y_train, 'train_clean_train_adv_eval')\n",
    "\n",
    "    print('Repeating the process, using adversarial training')\n",
    "\n",
    "  # Create a new model and train it to be robust to FastGradientMethod\n",
    "  model2 = ModelBasicCNN('model2', nb_classes, nb_filters)\n",
    "  fgsm2 = FastGradientMethod(model2, sess=sess)\n",
    "\n",
    "  def attack(x):\n",
    "    return fgsm2.generate(x, **fgsm_params)\n",
    "\n",
    "  loss2 = CrossEntropy(model2, smoothing=label_smoothing, attack=attack)\n",
    "  preds2 = model2.get_logits(x)\n",
    "  adv_x2 = attack(x)\n",
    "\n",
    "  if not backprop_through_attack:\n",
    "    # For the fgsm attack used in this tutorial, the attack has zero\n",
    "    # gradient so enabling this flag does not change the gradient.\n",
    "    # For some other attacks, enabling this flag increases the cost of\n",
    "    # training, but gives the defender the ability to anticipate how\n",
    "    # the atacker will change their strategy in response to updates to\n",
    "    # the defender's parameters.\n",
    "    adv_x2 = tf.stop_gradient(adv_x2)\n",
    "  preds2_adv = model2.get_logits(adv_x2)\n",
    "\n",
    "  def evaluate2():\n",
    "    # Accuracy of adversarially trained model on legitimate test inputs\n",
    "    do_eval(preds2, x_test, y_test, 'adv_train_clean_eval', False)\n",
    "    # Accuracy of the adversarially trained model on adversarial examples\n",
    "    do_eval(preds2_adv, x_test, y_test, 'adv_train_adv_eval', True)\n",
    "\n",
    "  # Perform and evaluate adversarial training\n",
    "  train(sess, loss2, x_train, y_train, evaluate=evaluate2,\n",
    "        args=train_params, rng=rng, var_list=model2.get_params())\n",
    "\n",
    "  # Calculate training errors\n",
    "  if testing:\n",
    "    do_eval(preds2, x_train, y_train, 'train_adv_train_clean_eval')\n",
    "    do_eval(preds2_adv, x_train, y_train, 'train_adv_train_adv_eval')\n",
    "\n",
    "  return report\n",
    "\n",
    "\n",
    "def main(argv=None):\n",
    "\n",
    "  mnist_tutorial(nb_epochs=NB_EPOCHS, batch_size=BATCH_SIZE,\n",
    "                 learning_rate=LEARNING_RATE,\n",
    "                 clean_train=CLEAN_TRAIN,\n",
    "                 backprop_through_attack=BACKPROP_THROUGH_ATTACK,\n",
    "                 nb_filters=NB_FILTERS)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "book5",
   "language": "python",
   "name": "book5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
