{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-1-0b225cc4bd90>:13: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /mnt/opt/anaconda2/envs/book5/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /mnt/opt/anaconda2/envs/book5/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /mnt/opt/anaconda2/envs/book5/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /mnt/opt/anaconda2/envs/book5/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /mnt/opt/anaconda2/envs/book5/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "#参考：https://github.com/LTS4/universal/blob/master/python/demo_inception.py\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "from tensorflow.python.framework import graph_util\n",
    "from tensorflow.python.platform import gfile\n",
    "import os\n",
    "\n",
    "#模型文件\n",
    "pb_file_path=\"tensorflow_mnist_graph.pb\"\n",
    "\n",
    "#mnist数据\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "\n",
    "#预测用的会话\n",
    "persisted_sess = tf.Session()\n",
    "# Load the Inception model\n",
    "with gfile.FastGFile(pb_file_path, 'rb') as f:\n",
    "        graph_def = tf.GraphDef()\n",
    "        graph_def.ParseFromString(f.read())\n",
    "        persisted_sess.graph.as_default()\n",
    "        tf.import_graph_def(graph_def, name='')\n",
    "\n",
    "        \n",
    "persisted_sess.graph.get_operations()\n",
    "#记载输入和输出Tensor\n",
    "persisted_input = persisted_sess.graph.get_tensor_by_name(\"input:0\")\n",
    "persisted_keep_prob = persisted_sess.graph.get_tensor_by_name(\"keep_prob:0\")\n",
    "persisted_output = persisted_sess.graph.get_tensor_by_name(\"output:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Computing feedforward function...\n"
     ]
    }
   ],
   "source": [
    "print('>> Computing feedforward function...')\n",
    "def f(image_inp,keep_prob=1.0): \n",
    "    return persisted_sess.run(persisted_output, \n",
    "                              feed_dict={persisted_input: image_inp,persisted_keep_prob:keep_prob})\n",
    "\n",
    "#数据已经归一化\n",
    "test_x=mnist.test.images\n",
    "test_y=mnist.test.labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9819\n",
      "FOOLING RATE =  0.0181\n"
     ]
    }
   ],
   "source": [
    "#批量验证测试集的准确率\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_pred=np.argmax(f(test_x),axis=1)\n",
    "y_true=np.argmax(test_y,axis=1)\n",
    "\n",
    "print(accuracy_score(y_true, y_pred, normalize=True))\n",
    "\n",
    "num_images=test_x.shape[0]\n",
    "\n",
    "fooling_rate = float(np.sum(y_pred != y_true) / float(num_images))\n",
    "print('FOOLING RATE = ', fooling_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jacobian(y_flat, x, inds):\n",
    "    n = 10 \n",
    "    loop_vars = [\n",
    "         tf.constant(0, tf.int32),\n",
    "         tf.TensorArray(tf.float32, size=n),\n",
    "    ]\n",
    "    _, jacobian = tf.while_loop(\n",
    "        lambda j,_: j < n,\n",
    "        lambda j,result: (j+1, result.write(j, tf.gradients(y_flat[inds[j]], x))),\n",
    "        loop_vars)\n",
    "    return jacobian.stack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deepfool(image, f, grads, num_classes=10, overshoot=0.02, max_iter=50):\n",
    "\n",
    "    f_image = np.array(f(image)).flatten()\n",
    "    I = (np.array(f_image)).flatten().argsort()[::-1]\n",
    "\n",
    "    I = I[0:num_classes]\n",
    "    label = I[0]\n",
    "\n",
    "    input_shape = image.shape\n",
    "    pert_image = image\n",
    "\n",
    "    f_i = np.array(f(pert_image)).flatten()\n",
    "    k_i = int(np.argmax(f_i))\n",
    "\n",
    "    w = np.zeros(input_shape)\n",
    "    r_tot = np.zeros(input_shape)\n",
    "\n",
    "    loop_i = 0\n",
    "\n",
    "    while k_i == label and loop_i < max_iter:\n",
    "\n",
    "        pert = np.inf\n",
    "        gradients = np.asarray(grads(pert_image,I))\n",
    "        \n",
    "        for k in range(1, num_classes):\n",
    "\n",
    "            # set new w_k and new f_k\n",
    "            #w_k = gradients[k, :, :, :, :] - gradients[0, :, :, :, :]\n",
    "            w_k = gradients[k, :, :] - gradients[0, :, :]\n",
    "            f_k = f_i[I[k]] - f_i[I[0]]\n",
    "            pert_k = abs(f_k)/np.linalg.norm(w_k.flatten())\n",
    "\n",
    "            # determine which w_k to use\n",
    "            if pert_k < pert:\n",
    "                pert = pert_k\n",
    "                w = w_k\n",
    "\n",
    "        # compute r_i and r_tot\n",
    "        r_i =  pert * w / np.linalg.norm(w)\n",
    "        r_tot = r_tot + r_i\n",
    "\n",
    "        # compute new perturbed image\n",
    "        pert_image = image + (1+overshoot)*r_tot\n",
    "        loop_i += 1\n",
    "\n",
    "        # compute new label\n",
    "        f_i = np.array(f(pert_image)).flatten()\n",
    "        k_i = int(np.argmax(f_i))\n",
    "\n",
    "    r_tot = (1+overshoot)*r_tot\n",
    "\n",
    "    return r_tot, loop_i, k_i, pert_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proj_lp(v, xi, p):\n",
    "\n",
    "    # Project on the lp ball centered at 0 and of radius xi\n",
    "\n",
    "    # SUPPORTS only p = 2 and p = Inf for now\n",
    "    if p == 2:\n",
    "        v = v * min(1, xi/np.linalg.norm(v.flatten(1)))\n",
    "    elif p == np.inf:\n",
    "        v = np.sign(v) * np.minimum(abs(v), xi)\n",
    "    else:\n",
    "         raise ValueError('Values of p different from 2 and Inf are currently not supported...')\n",
    "\n",
    "    return v\n",
    "\n",
    "def universal_perturbation(dataset, f, grads, delta=0.2, max_iter_uni = np.inf, xi=10, p=np.inf, num_classes=10, overshoot=0.02, max_iter_df=10):\n",
    "\n",
    "    v = 0\n",
    "    fooling_rate = 0.0\n",
    "    num_images =  np.shape(dataset)[0] # The images should be stacked ALONG FIRST DIMENSION\n",
    "    print(\"X size:{}\".format(num_images))\n",
    "\n",
    "    itr = 0\n",
    "    while fooling_rate < 1-delta and itr < max_iter_uni:\n",
    "        # Shuffle the dataset\n",
    "        np.random.shuffle(dataset)\n",
    "\n",
    "        print ('Starting pass number ', itr)\n",
    "\n",
    "        # Go through the data set and compute the perturbation increments sequentially\n",
    "        for k in range(0, num_images):\n",
    "            #cur_img = dataset[k:(k+1), :, :, :]\n",
    "            cur_img = dataset[k:(k+1), :]\n",
    "\n",
    "            if int(np.argmax(np.array(f(cur_img)).flatten())) == int(np.argmax(np.array(f(cur_img+v)).flatten())):\n",
    "                #print('>> k = ', k, ', pass #', itr)\n",
    "\n",
    "                # Compute adversarial perturbation\n",
    "                dr,iter,_,_ = deepfool(cur_img + v, f, grads, num_classes=num_classes, overshoot=overshoot, max_iter=max_iter_df)\n",
    "\n",
    "                # Make sure it converged...\n",
    "                if iter < max_iter_df-1:\n",
    "                    v = v + dr\n",
    "\n",
    "                    # Project on l_p ball\n",
    "                    v = proj_lp(v, xi, p)\n",
    "\n",
    "        itr = itr + 1\n",
    "\n",
    "        # Perturb the dataset with computed perturbation\n",
    "        dataset_perturbed = dataset + v\n",
    "\n",
    "        est_labels_pert=np.argmax(f(dataset_perturbed),axis=1)\n",
    "        est_labels_orig=np.argmax(f(dataset),axis=1)\n",
    "\n",
    "\n",
    "       \n",
    "        # Compute the fooling rate\n",
    "        fooling_rate = float(np.sum(est_labels_pert != est_labels_orig) / float(num_images))\n",
    "        print('FOOLING RATE = ', fooling_rate)\n",
    "\n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Computing gradient function...\n",
      "X size:10000\n",
      "Starting pass number  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/opt/anaconda2/envs/book5/lib/python3.6/site-packages/ipykernel_launcher.py:31: RuntimeWarning: divide by zero encountered in float_scalars\n",
      "/mnt/opt/anaconda2/envs/book5/lib/python3.6/site-packages/ipykernel_launcher.py:39: RuntimeWarning: invalid value encountered in multiply\n",
      "/mnt/opt/anaconda2/envs/book5/lib/python3.6/site-packages/ipykernel_launcher.py:9: RuntimeWarning: invalid value encountered in minimum\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOOLING RATE =  0.9029\n"
     ]
    }
   ],
   "source": [
    "X=test_x.copy()\n",
    "\n",
    "y_flat = tf.reshape(persisted_output, (-1,))\n",
    "inds = tf.placeholder(tf.int32, shape=(10,))\n",
    "dydx = jacobian(y_flat,persisted_input,inds)\n",
    "\n",
    "print('>> Computing gradient function...')\n",
    "def grad_fs(image_inp, indices,keep_prob=1.0): \n",
    "    return persisted_sess.run(dydx, feed_dict={persisted_input: image_inp, inds: indices,persisted_keep_prob:keep_prob}).squeeze(axis=1)\n",
    "\n",
    "# Running universal perturbation\n",
    "v = universal_perturbation(X, f, grad_fs, delta=0.2,num_classes=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0974\n",
      "FOOLING RATE =  0.9026\n"
     ]
    }
   ],
   "source": [
    "y_pred=np.argmax(f(test_x+v),axis=1)\n",
    "y_true=np.argmax(test_y,axis=1)\n",
    "\n",
    "print(accuracy_score(y_true, y_pred, normalize=True))\n",
    "\n",
    "num_images=test_x.shape[0]\n",
    "\n",
    "fooling_rate = float(np.sum(y_pred != y_true) / float(num_images))\n",
    "print('FOOLING RATE = ', fooling_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "book5",
   "language": "python",
   "name": "book5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
