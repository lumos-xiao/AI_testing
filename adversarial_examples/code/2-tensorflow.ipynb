{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 基于MNIST训练集生成Universal adversarial perturbations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-1-7377e5bca87e>:11: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /mnt/opt/anaconda2/envs/book5/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /mnt/opt/anaconda2/envs/book5/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /mnt/opt/anaconda2/envs/book5/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /mnt/opt/anaconda2/envs/book5/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /mnt/opt/anaconda2/envs/book5/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From <ipython-input-1-7377e5bca87e>:35: arg_max (from tensorflow.python.ops.gen_math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `argmax` instead\n",
      "loss=2.3025851249694824,acc=0.25519999861717224\n",
      "loss=0.21335826814174652,acc=0.9430999755859375\n",
      "loss=0.27882134914398193,acc=0.9559999704360962\n",
      "loss=0.14894792437553406,acc=0.9674000144004822\n",
      "loss=0.08424727618694305,acc=0.9729999899864197\n",
      "loss=0.03655862808227539,acc=0.9728000164031982\n",
      "loss=0.06975220888853073,acc=0.9761999845504761\n",
      "loss=0.05614079535007477,acc=0.9758999943733215\n",
      "loss=0.04887697845697403,acc=0.9764999747276306\n",
      "loss=0.15488292276859283,acc=0.9753000140190125\n",
      "loss=0.045302845537662506,acc=0.9782000184059143\n",
      "loss=0.057981591671705246,acc=0.9785000085830688\n",
      "loss=0.08565492928028107,acc=0.9783999919891357\n",
      "loss=0.0596313439309597,acc=0.9796000123023987\n",
      "loss=0.0647026002407074,acc=0.9812999963760376\n",
      "loss=0.04304274171590805,acc=0.9818999767303467\n",
      "loss=0.0752335637807846,acc=0.9814000129699707\n",
      "loss=0.0761272981762886,acc=0.98089998960495\n",
      "loss=0.022767717018723488,acc=0.9810000061988831\n",
      "loss=0.023966539651155472,acc=0.9801999926567078\n",
      "loss=0.017990536987781525,acc=0.9810000061988831\n",
      "loss=0.019831836223602295,acc=0.980400025844574\n",
      "loss=0.03567279502749443,acc=0.9824000000953674\n",
      "loss=0.04704804718494415,acc=0.9825000166893005\n",
      "loss=0.011448821052908897,acc=0.9805999994277954\n",
      "INFO:tensorflow:Froze 4 variables.\n",
      "INFO:tensorflow:Converted 4 variables to const ops.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "from tensorflow.python.framework import graph_util\n",
    "import os\n",
    "\n",
    "pb_file_path=\"tensorflow_mnist_graph.pb\"\n",
    "\n",
    "g = tf.Graph()\n",
    "with tf.Session(graph=g) as sess:\n",
    "\n",
    "    mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "    in_units = 784 #输入节点数\n",
    "    h1_units = 300 #隐含层节点数\n",
    "\n",
    "    #初始化隐含层权重W1，服从默认均值为0，标准差为0.1的截断正态分布\n",
    "    W1 = tf.Variable(tf.truncated_normal([in_units, h1_units], stddev=0.1)) \n",
    "    b1 = tf.Variable(tf.zeros([h1_units])) #隐含层偏置b1全部初始化为0\n",
    "    W2 = tf.Variable(tf.zeros([h1_units, 10])) \n",
    "    b2 = tf.Variable(tf.zeros([10]))\n",
    "    x = tf.placeholder(tf.float32, [None, in_units],name=\"input\")\n",
    "    keep_prob = tf.placeholder(tf.float32,name=\"keep_prob\") \n",
    "\n",
    "    #定义模型结构\n",
    "    hidden1 = tf.nn.relu(tf.matmul(x, W1) + b1)\n",
    "    hidden1_drop = tf.nn.dropout(hidden1, keep_prob)\n",
    "    y = tf.nn.softmax(tf.matmul(hidden1_drop, W2) + b2,name=\"output\")\n",
    "\n",
    "    #训练部分\n",
    "    y_ = tf.placeholder(tf.float32, [None, 10])\n",
    "    cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y), reduction_indices=[1]))\n",
    "    train_step = tf.train.AdagradOptimizer(0.3).minimize(cross_entropy)\n",
    "\n",
    "\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    correct_prediction = tf.equal(tf.arg_max(y, 1), tf.arg_max(y_, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    \n",
    "    writer = tf.summary.FileWriter('/tmp/logs/', sess.graph)\n",
    "    \n",
    "    \n",
    "    for i in range(5000):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(100) \n",
    "        _,loss=sess.run([train_step,cross_entropy],{x: batch_xs, y_: batch_ys, keep_prob: 0.75})\n",
    "        \n",
    "        if i % 200 == 0:\n",
    "            acc=accuracy.eval(feed_dict={x:mnist.test.images,y_:mnist.test.labels,keep_prob:1})\n",
    "            print(\"loss={},acc={}\".format(loss,acc))\n",
    "\n",
    "\n",
    "    constant_graph = graph_util.convert_variables_to_constants(sess, sess.graph_def, output_node_names=[\"output\"])\n",
    "\n",
    "    with tf.gfile.FastGFile(pb_file_path, mode='wb') as f:\n",
    "        f.write(constant_graph.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "book5",
   "language": "python",
   "name": "book5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
