{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "介绍如何攻击tensorflow的pb格式模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#把id转换成可读字符串\n",
    "#参考：https://github.com/tensorflow/models/blob/1af55e018eebce03fb61bba9959a04672536107d/tutorials/image/imagenet/classify_image.py\n",
    "class NodeLookup(object):\n",
    "  \"\"\"Converts integer node ID's to human readable labels.\"\"\"\n",
    "\n",
    "  def __init__(self,\n",
    "               label_lookup_path=None,\n",
    "               uid_lookup_path=None):\n",
    "    if not label_lookup_path:\n",
    "      label_lookup_path = 'models/imagenet_2012_challenge_label_map_proto.pbtxt'\n",
    "    if not uid_lookup_path:\n",
    "      uid_lookup_path = 'models/imagenet_synset_to_human_label_map.txt'\n",
    "    self.node_lookup = self.load(label_lookup_path, uid_lookup_path)\n",
    "\n",
    "  def load(self, label_lookup_path, uid_lookup_path):\n",
    "    \"\"\"Loads a human readable English name for each softmax node.\n",
    "    Args:\n",
    "      label_lookup_path: string UID to integer node ID.\n",
    "      uid_lookup_path: string UID to human-readable string.\n",
    "    Returns:\n",
    "      dict from integer node ID to human-readable string.\n",
    "    \"\"\"\n",
    "    if not tf.gfile.Exists(uid_lookup_path):\n",
    "      tf.logging.fatal('File does not exist %s', uid_lookup_path)\n",
    "    if not tf.gfile.Exists(label_lookup_path):\n",
    "      tf.logging.fatal('File does not exist %s', label_lookup_path)\n",
    "\n",
    "    # Loads mapping from string UID to human-readable string\n",
    "    proto_as_ascii_lines = tf.gfile.GFile(uid_lookup_path).readlines()\n",
    "    uid_to_human = {}\n",
    "    p = re.compile(r'[n\\d]*[ \\S,]*')\n",
    "    for line in proto_as_ascii_lines:\n",
    "      parsed_items = p.findall(line)\n",
    "      uid = parsed_items[0]\n",
    "      human_string = parsed_items[2]\n",
    "      uid_to_human[uid] = human_string\n",
    "\n",
    "    # Loads mapping from string UID to integer node ID.\n",
    "    node_id_to_uid = {}\n",
    "    proto_as_ascii = tf.gfile.GFile(label_lookup_path).readlines()\n",
    "    for line in proto_as_ascii:\n",
    "      if line.startswith('  target_class:'):\n",
    "        target_class = int(line.split(': ')[1])\n",
    "      if line.startswith('  target_class_string:'):\n",
    "        target_class_string = line.split(': ')[1]\n",
    "        node_id_to_uid[target_class] = target_class_string[1:-2]\n",
    "\n",
    "    # Loads the final mapping of integer node ID to human-readable string\n",
    "    node_id_to_name = {}\n",
    "    for key, val in node_id_to_uid.items():\n",
    "      if val not in uid_to_human:\n",
    "        tf.logging.fatal('Failed to locate: %s', val)\n",
    "      name = uid_to_human[val]\n",
    "      node_id_to_name[key] = name\n",
    "\n",
    "    return node_id_to_name\n",
    "\n",
    "  def id_to_string(self, node_id):\n",
    "    if node_id not in self.node_lookup:\n",
    "      return ''\n",
    "    return self.node_lookup[node_id]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#加载解码的图像 这里是个大坑 tf提供的imagenet预训练好的模型pb文件中 包含针对图像的预处理环节 即解码jpg文件 这部分没有梯度\n",
    "#需要直接处理解码后的数据\n",
    "session=tf.Session()\n",
    "\n",
    "#adv为对抗样本 可以被训练和修改的量\n",
    "adv = tf.get_variable(name=\"adv\", shape=[1,100,100,3], dtype=tf.float32, initializer=tf.zeros_initializer)\n",
    "\n",
    "\n",
    "#x = tf.placeholder(tf.float32, shape=[1,100,100,3])\n",
    "target = tf.placeholder(tf.int32)\n",
    "#assign_op=tf.assign(adv, x)\n",
    "\n",
    "def create_graph(dirname):\n",
    "    with tf.gfile.FastGFile(dirname, 'rb') as f:\n",
    "        graph_def = session.graph_def\n",
    "        graph_def.ParseFromString(f.read())\n",
    "\n",
    "        _ = tf.import_graph_def(graph_def, name='adv',\n",
    "                                input_map={\"ExpandDims:0\":adv} )\n",
    "\n",
    "#从'http://download.tensorflow.org/models/image/imagenet/inception-2015-12-05.tgz'下载并解压到指定路径\n",
    "create_graph(\"models/classify_image_graph_def.pb\")\n",
    "\n",
    "# 初始化参数  非常重要\n",
    "session.run(tf.global_variables_initializer())\n",
    "tensorlist=[n.name for n in session.graph_def.node]\n",
    "\n",
    "#print(tensorlist)\n",
    "\n",
    "#这里注意 一定要查看下当前tensor的名称再写 因为导入pb时指定了名称前缀adv\n",
    "softmax_tensor = session.graph.get_tensor_by_name('adv_1/softmax:0')\n",
    "#input_tensor=session.graph.get_tensor_by_name('ExpandDims:0')\n",
    "logits_tensor=session.graph.get_tensor_by_name('adv_1/softmax/logits:0')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "giant panda, panda, panda bear, coon bear, Ailuropoda melanoleuca (score = 0.89233)(id = 169)\n",
      "indri, indris, Indri indri, Indri brevicaudatus (score = 0.00859)(id = 75)\n",
      "lesser panda, red panda, panda, bear cat, cat bear, Ailurus fulgens (score = 0.00264)(id = 7)\n"
     ]
    }
   ],
   "source": [
    "imagename=\"../picture/cropped_panda.jpg\"\n",
    "\n",
    "image=np.array(Image.open(imagename).convert('RGB')).astype(np.float32)\n",
    "#[100,100,3]->[1,100,100,3]\n",
    "image=np.expand_dims(image, axis=0)\n",
    "\n",
    "predictions = session.run(softmax_tensor,\n",
    "                           {adv: image})\n",
    "predictions = np.squeeze(predictions)\n",
    "\n",
    "# Creates node ID --> English string lookup.\n",
    "node_lookup = NodeLookup()\n",
    "\n",
    "#top 3\n",
    "top_k = predictions.argsort()[-3:][::-1]\n",
    "for node_id in top_k:\n",
    "    human_string = node_lookup.id_to_string(node_id)\n",
    "    score = predictions[node_id]\n",
    "    print('%s (score = %.5f)(id = %d)' % (human_string, score,node_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "开始迭代计算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=0 loss=[9.84747] label=169\n",
      "epoch=1 loss=[9.063099] label=169\n",
      "epoch=2 loss=[8.505758] label=169\n",
      "epoch=3 loss=[8.120972] label=169\n",
      "epoch=4 loss=[7.854911] label=169\n",
      "epoch=5 loss=[7.6450825] label=169\n",
      "epoch=6 loss=[7.4593973] label=169\n",
      "epoch=7 loss=[7.2938056] label=169\n",
      "epoch=8 loss=[7.130396] label=169\n",
      "epoch=9 loss=[6.9812517] label=169\n",
      "epoch=10 loss=[6.8430085] label=169\n",
      "epoch=11 loss=[6.6977453] label=169\n",
      "epoch=12 loss=[6.552574] label=169\n",
      "epoch=13 loss=[6.4041405] label=169\n",
      "epoch=14 loss=[6.250405] label=169\n",
      "epoch=15 loss=[6.090739] label=169\n",
      "epoch=16 loss=[5.935956] label=169\n",
      "epoch=17 loss=[5.779936] label=169\n",
      "epoch=18 loss=[5.6254787] label=169\n",
      "epoch=19 loss=[5.471655] label=169\n",
      "epoch=20 loss=[5.3071976] label=169\n",
      "epoch=21 loss=[5.136609] label=169\n",
      "epoch=22 loss=[4.9547234] label=169\n",
      "epoch=23 loss=[4.766656] label=169\n",
      "epoch=24 loss=[4.578465] label=169\n",
      "epoch=25 loss=[4.3786206] label=169\n",
      "epoch=26 loss=[4.168749] label=169\n",
      "epoch=27 loss=[3.9431925] label=169\n",
      "epoch=28 loss=[3.7050753] label=169\n",
      "epoch=29 loss=[3.45778] label=169\n",
      "epoch=30 loss=[3.1900342] label=169\n",
      "epoch=31 loss=[2.9023836] label=169\n",
      "epoch=32 loss=[2.6293871] label=169\n",
      "epoch=33 loss=[2.3296964] label=169\n",
      "epoch=34 loss=[2.0458288] label=288\n",
      "snowmobile (score = 0.12927)(id = 288)\n",
      "giant panda, panda, panda bear, coon bear, Ailuropoda melanoleuca (score = 0.12047)(id = 169)\n",
      "indri, indris, Indri indri, Indri brevicaudatus (score = 0.04191)(id = 75)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "epochs=500\n",
    "lr=0.1\n",
    "target_label=288\n",
    "\n",
    "cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits_tensor, labels=[target])\n",
    "#optimizer = tf.train.GradientDescentOptimizer(lr)\n",
    "optimizer = tf.train.AdamOptimizer(lr)\n",
    "train_step=optimizer.minimize(loss=cross_entropy,var_list=[adv])\n",
    "\n",
    "# 初始化参数  非常重要 Adam的参数也需要这样初始化 GradientDescent可以省略这一步\n",
    "session.run(tf.global_variables_initializer())\n",
    "\n",
    "#初始化\n",
    "session.run(tf.assign(adv, image))\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    loss,_,adv_img,predictions=session.run([cross_entropy,train_step,adv,softmax_tensor],{target:target_label})\n",
    "    \n",
    "    predictions = np.squeeze(predictions)\n",
    "    label=np.argmax(predictions)\n",
    "    \n",
    "    print(\"epoch={} loss={} label={}\".format(epoch,loss,label))\n",
    "    \n",
    "    #如果定向攻击成功\n",
    "    if label == target_label:\n",
    "        top_k = predictions.argsort()[-3:][::-1]\n",
    "        for node_id in top_k:\n",
    "            human_string = node_lookup.id_to_string(node_id)\n",
    "            score = predictions[node_id]\n",
    "            print('%s (score = %.5f)(id = %d)' % (human_string, score,node_id))\n",
    "        break  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "book5",
   "language": "python",
   "name": "book5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
